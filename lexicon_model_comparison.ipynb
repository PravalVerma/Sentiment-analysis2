{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9322c21-1fb2-4061-88cb-38db76f467ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment Analysis:\n",
      "Accuracy: 0.9375\n",
      "Precision (Positive, Negative, Neutral): [0.95401662 0.80625    0.68571429]\n",
      "Recall (Positive, Negative, Neutral): [0.98175599 0.62621359 0.6       ]\n",
      "F1 Score (Positive, Negative, Neutral): [0.96768755 0.70491803 0.64      ]\n",
      "\n",
      "SentiWordNet Sentiment Analysis:\n",
      "Accuracy: 0.793\n",
      "Precision (Positive, Negative, Neutral): [0.92718142 0.30924855 0.03278689]\n",
      "Recall (Positive, Negative, Neutral): [0.84207526 0.51941748 0.05      ]\n",
      "F1 Score (Positive, Negative, Neutral): [0.88258142 0.38768116 0.03960396]\n",
      "\n",
      "LIWC Sentiment Analysis:\n",
      "Accuracy: 0.287\n",
      "Precision (Positive, Negative, Neutral): [0.96052632 0.31325301 0.0267148 ]\n",
      "Recall (Positive, Negative, Neutral): [0.29133409 0.12621359 0.925     ]\n",
      "F1 Score (Positive, Negative, Neutral): [0.44706912 0.1799308  0.05192982]\n",
      "\n",
      "General Inquirer Sentiment Analysis:\n",
      "Accuracy: 0.616\n",
      "Precision (Positive, Negative, Neutral): [0.94817814 0.49122807 0.04661017]\n",
      "Recall (Positive, Negative, Neutral): [0.66761688 0.13592233 0.825     ]\n",
      "F1 Score (Positive, Negative, Neutral): [0.78353965 0.21292776 0.08823529]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from collections import Counter \n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"sentiment_categorized_reviews.csv\")\n",
    "df = df.head(10000)\n",
    "\n",
    "# Define a function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Preprocess text data\n",
    "df['Cleaned_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Text'], df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize VADER SentimentIntensityAnalyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment using VADER\n",
    "def calculate_vader_sentiment(text):\n",
    "    sentiment_score = vader_analyzer.polarity_scores(text)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Calculate VADER sentiment on test set\n",
    "vader_predictions = X_test.apply(calculate_vader_sentiment)\n",
    "\n",
    "# Function to calculate sentiment using SentiWordNet\n",
    "def calculate_sentiwordnet_sentiment(text):\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    for token in tokens:\n",
    "        synsets = list(swn.senti_synsets(token))\n",
    "        if synsets:\n",
    "            synset = synsets[0]  # Take the first synset\n",
    "            pos_score += synset.pos_score()\n",
    "            neg_score += synset.neg_score()\n",
    "    if pos_score > neg_score:\n",
    "        return 'Positive'\n",
    "    elif neg_score > pos_score:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Calculate SentiWordNet sentiment on test set\n",
    "sentiwordnet_predictions = X_test.apply(calculate_sentiwordnet_sentiment)\n",
    "\n",
    "# Function to calculate sentiment using LIWC (replace with your actual LIWC lexicon)\n",
    "def calculate_liwc_sentiment(text):\n",
    "  # Example LIWC categories (replace with actual LIWC categories and their sentiment scores)\n",
    "  liwc_categories = {\n",
    "      'positive_emotion': ['happy', 'joy', 'excited'],\n",
    "      'negative_emotion': ['sad', 'angry', 'disappointed'],\n",
    "      'positive_social': ['friend', 'love', 'family'],\n",
    "      'negative_social': ['hate', 'enemy', 'alone'],\n",
    "  }\n",
    "\n",
    "  # Count word occurrences in LIWC categories\n",
    "  category_counts = Counter({category: 0 for category in liwc_categories})\n",
    "  for token in word_tokenize(text.lower()):\n",
    "    for category, words in liwc_categories.items():\n",
    "      if token in words:\n",
    "        category_counts[category] += 1\n",
    "\n",
    "  # Calculate sentiment score based on category counts (adjust weights as needed)\n",
    "  sentiment_score = 0\n",
    "  sentiment_score += category_counts['positive_emotion'] * 2\n",
    "  sentiment_score -= category_counts['negative_emotion'] * 1.5\n",
    "  sentiment_score += category_counts['positive_social'] * 1\n",
    "  sentiment_score -= category_counts['negative_social'] * 1\n",
    "\n",
    "  if sentiment_score > 0:\n",
    "    return 'Positive'\n",
    "  elif sentiment_score < 0:\n",
    "    return 'Negative'\n",
    "  else:\n",
    "    return 'Neutral'\n",
    "\n",
    "# Calculate LIWC sentiment on test set\n",
    "liwc_predictions = X_test.apply(calculate_liwc_sentiment)\n",
    "\n",
    "# Function to calculate sentiment using General Inquirer (replace with your actual GI lexicon)\n",
    "def calculate_general_inquirer_sentiment(text):\n",
    "  # Example General Inquirer categories (replace with actual GI categories and their sentiment scores)\n",
    "  gi_categories = {\n",
    "      'positive': ['good', 'great', 'wonderful', 'like'],\n",
    "      'negative': ['bad', 'terrible', 'horrible', 'dislike'],\n",
    "      'strong_positive': ['excellent', 'fantastic', 'amazing'],\n",
    "      'strong_negative': ['awful', 'dreadful', 'appalling'],\n",
    "  }\n",
    "# Count word occurrences in GI categories\n",
    "  category_counts = Counter({category: 0 for category in gi_categories})\n",
    "  for token in word_tokenize(text.lower()):\n",
    "    for category, words in gi_categories.items():\n",
    "      if token in words:\n",
    "        category_counts[category] += 1\n",
    "\n",
    "  # Calculate sentiment score based on category counts (adjust weights as needed)\n",
    "  sentiment_score = 0\n",
    "  sentiment_score += category_counts['positive'] + category_counts['strong_positive'] * 2\n",
    "  sentiment_score -= category_counts['negative'] + category_counts['strong_negative'] * 2\n",
    "\n",
    "  if sentiment_score > 0:\n",
    "    return 'Positive'\n",
    "  elif sentiment_score < 0:\n",
    "    return 'Negative'\n",
    "  else:\n",
    "    return 'Neutral'\n",
    "\n",
    "# Calculate General Inquirer sentiment on test set\n",
    "general_inquirer_predictions = X_test.apply(calculate_general_inquirer_sentiment)\n",
    "\n",
    "# Function to evaluate function with improved handling for label distribution\n",
    "def evaluate_predictions(predictions, true_labels):\n",
    "  # Calculate evaluation metrics (with zero_division=1)\n",
    "  accuracy = accuracy_score(true_labels, predictions)\n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average=None, labels=['Positive', 'Negative', 'Neutral'], zero_division=1)\n",
    "  return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate VADER predictions with improved evaluation function\n",
    "vader_accuracy, vader_precision, vader_recall, vader_f1 = evaluate_predictions(vader_predictions, y_test)\n",
    "\n",
    "# Evaluate SentiWordNet predictions with improved evaluation function\n",
    "sentiwordnet_accuracy, sentiwordnet_precision, sentiwordnet_recall, sentiwordnet_f1 = evaluate_predictions(sentiwordnet_predictions, y_test)\n",
    "\n",
    "# Evaluate LIWC predictions with improved evaluation function\n",
    "liwc_accuracy, liwc_precision, liwc_recall, liwc_f1 = evaluate_predictions(liwc_predictions, y_test)\n",
    "\n",
    "# Evaluate General Inquirer predictions with improved evaluation function\n",
    "general_inquirer_accuracy, general_inquirer_precision, general_inquirer_recall, general_inquirer_f1 = evaluate_predictions(general_inquirer_predictions, y_test)\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"VADER Sentiment Analysis:\")\n",
    "print(\"Accuracy:\", vader_accuracy)\n",
    "print(\"Precision (Positive, Negative, Neutral):\", vader_precision)\n",
    "print(\"Recall (Positive, Negative, Neutral):\", vader_recall)\n",
    "print(\"F1 Score (Positive, Negative, Neutral):\", vader_f1)\n",
    "\n",
    "print(\"\\nSentiWordNet Sentiment Analysis:\")\n",
    "print(\"Accuracy:\", sentiwordnet_accuracy)\n",
    "print(\"Precision (Positive, Negative, Neutral):\", sentiwordnet_precision)\n",
    "print(\"Recall (Positive, Negative, Neutral):\", sentiwordnet_recall)\n",
    "print(\"F1 Score (Positive, Negative, Neutral):\", sentiwordnet_f1)\n",
    "\n",
    "print(\"\\nLIWC Sentiment Analysis:\")\n",
    "print(\"Accuracy:\", liwc_accuracy)\n",
    "print(\"Precision (Positive, Negative, Neutral):\", liwc_precision)\n",
    "print(\"Recall (Positive, Negative, Neutral):\", liwc_recall)\n",
    "print(\"F1 Score (Positive, Negative, Neutral):\", liwc_f1)\n",
    "\n",
    "print(\"\\nGeneral Inquirer Sentiment Analysis:\")\n",
    "print(\"Accuracy:\", general_inquirer_accuracy)\n",
    "print(\"Precision (Positive, Negative, Neutral):\", general_inquirer_precision)A\n",
    "print(\"Recall (Positive, Negative, Neutral):\", general_inquirer_recall)\n",
    "print(\"F1 Score (Positive, Negative, Neutral):\", general_inquirer_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f886c9-1fad-4029-9691-aeaefe25f344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
