{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6142c34-afb2-4df0-98cc-20ecfe46bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"sentiment_categorized_reviews.csv\")\n",
    "\n",
    "# Define a function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Preprocess text data\n",
    "df['Cleaned_Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Text'], df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Define and train Support Vector Machines (SVM) model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Initialize VADER SentimentIntensityAnalyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment using VADER\n",
    "def calculate_vader_sentiment(text):\n",
    "    sentiment_score = vader_analyzer.polarity_scores(text)\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Calculate VADER sentiment on test set\n",
    "vader_predictions = X_test.apply(calculate_vader_sentiment)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Function to evaluate model with handling for undefined metrics\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(tfidf_vectorizer.transform(X_test))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, predictions, labels=['Negative', 'Positive', 'Neutral'], average=None, zero_division=1)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# Evaluate Naive Bayes model\n",
    "nb_accuracy, nb_precision, nb_recall, nb_f1 = evaluate_model(nb_model, X_test, y_test)\n",
    "\n",
    "# Evaluate SVM model\n",
    "svm_accuracy, svm_precision, svm_recall, svm_f1 = evaluate_model(svm_model, X_test, y_test)\n",
    "\n",
    "# Evaluate VADER model\n",
    "vader_accuracy = accuracy_score(y_test, vader_predictions)\n",
    "vader_precision, vader_recall, vader_f1, _ = precision_recall_fscore_support(y_test, vader_predictions, labels=['Negative', 'Positive', 'Neutral'], average=None)\n",
    "\n",
    "# Display results for Naive Bayes model\n",
    "print(\"Naive Bayes Model Metrics:\")\n",
    "print(\"Accuracy:\", nb_accuracy)\n",
    "print(\"Precision (Negative, Positive, Neutral):\", nb_precision)\n",
    "print(\"Recall (Negative, Positive, Neutral):\", nb_recall)\n",
    "print(\"F1 Score (Negative, Positive, Neutral):\", nb_f1)\n",
    "\n",
    "# Display results for SVM model\n",
    "print(\"\\nSupport Vector Machines (SVM) Model Metrics:\")\n",
    "print(\"Accuracy:\", svm_accuracy)\n",
    "print(\"Precision (Negative, Positive, Neutral):\", svm_precision)\n",
    "print(\"Recall (Negative, Positive, Neutral):\", svm_recall)\n",
    "print(\"F1 Score (Negative, Positive, Neutral):\", svm_f1)\n",
    "\n",
    "# Display results for VADER model\n",
    "print(\"\\nVADER Model Metrics:\")\n",
    "print(\"Accuracy:\", vader_accuracy)\n",
    "print(\"Precision (Negative, Positive, Neutral):\", vader_precision)\n",
    "print(\"Recall (Negative, Positive, Neutral):\", vader_recall)\n",
    "print(\"F1 Score (Negative, Positive, Neutral):\", vader_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603ab1a-2e89-49f2-b9a5-d380dc33a491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
